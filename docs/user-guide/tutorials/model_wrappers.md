# Model Wrappers

The `eva` framework is built on top of PyTorch Lightning and thus naturally supports loading pytorch models and checkpoints. In this tutorial, we show how to use `eva`'s model wrapper API (`eva.models.networks.wrappers`) to enable the evaluation of models trained & saved using other frameworks.


## HuggingFace Transformers Model Hub
For loading models `eva` provides a custom wrapper class `HuggingFaceModel` which can be used as follows:

```
class_path: eva.models.networks.wrappers.HuggingFaceModel
init_args:
    model_name_or_path: owkin/phikon
    tensor_transforms: 
        class_path: eva.vision.data.transforms.model_output.ExtractCLSFeatures
```

Note that in this example, we also need to provide a tensor transformation, which will be applied to the tensor generated by the model's forward pass. In this case, the `ExtractCLSFeatures` transformation will extract the features corresponding to the `CLS` token from the `ViT` model outputs.

## ONNX
For loading `.onnx` model checkpoints, eva provides the following wrapper class:

```
class_path: eva.models.networks.wrappers.ONNXModel
init_args:
    path: path/to/model.onnx
    device: cuda
```

## Implementing custom wrappers

To load models from other frameworks, you can also implement your own custom model wrappers, which need to subclass `eva.models.networks.wrappers.BaseModel` and implement the following abstract methods: 

- `load_model`: Returns an instantiated model object & loads pre-trained model weights from a checkpoint if available. 
- `model_forward`: Implements the forward pass of the model and returns the output as a `torch.Tensor` of shape `[embedding_dim]` or `[1,embedding_dim]`.

Note that tensor transformations can be also applied after `model_forward` by providing any `Callable` via the `tensor_transforms` argument of the `BaseModel` interface, as done in the HuggingFace wrapper example from above.

You can take the implementations of the `HuggingFaceModel` and `ONNXModel` wrappers as a reference.


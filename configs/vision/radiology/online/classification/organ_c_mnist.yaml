---
trainer:
  class_path: eva.Trainer
  init_args:
    n_runs: &N_RUNS ${oc.env:N_RUNS, 1}
    default_root_dir: &LIGHTNING_ROOT ${oc.env:LIGHTNING_ROOT, logs/dino_vits16/online/mhist}
    max_steps: &MAX_STEPS ${oc.env:MAX_STEPS, 12500}
    callbacks:
      - class_path: eva.callbacks.ConfigurationLogger
      - class_path: lightning.pytorch.callbacks.TQDMProgressBar
        init_args:
          refresh_rate: ${oc.env:TQDM_REFRESH_RATE, 1}
      - class_path: lightning.pytorch.callbacks.LearningRateMonitor
        init_args:
          logging_interval: epoch
      - class_path: lightning.pytorch.callbacks.ModelCheckpoint
        init_args:
          filename: best
          save_last: true
          save_top_k: 1
          monitor: &MONITOR_METRIC ${oc.env:MONITOR_METRIC, val/MulticlassAccuracy}
          mode: &MONITOR_METRIC_MODE ${oc.env:MONITOR_METRIC_MODE, max}
      - class_path: lightning.pytorch.callbacks.EarlyStopping
        init_args:
          min_delta: 0
          patience: 400
          monitor: *MONITOR_METRIC
          mode: *MONITOR_METRIC_MODE
    logger:
      - class_path: lightning.pytorch.loggers.TensorBoardLogger
        init_args:
          save_dir: *LIGHTNING_ROOT
          name: ""
model:
  class_path: eva.HeadModule
  init_args:
    backbone:
      class_path: eva.vision.models.ModelFromRegistry
      init_args:
        model_name: ${oc.env:MODEL_NAME, universal/vit_small_patch16_224_dino}
        model_extra_kwargs: ${oc.env:MODEL_EXTRA_KWARGS, null}
    head:
      class_path: torch.nn.Linear
      init_args:
        in_features: ${oc.env:IN_FEATURES, 384}
        out_features: &NUM_CLASSES 11
    criterion: torch.nn.CrossEntropyLoss
    optimizer:
      class_path: torch.optim.AdamW
      init_args:
        lr: ${oc.env:LR_VALUE, 0.0003}
    lr_scheduler:
      class_path: torch.optim.lr_scheduler.CosineAnnealingLR
      init_args:
        T_max: *MAX_STEPS
        eta_min: 0.0
    metrics:
      common:
        - class_path: eva.metrics.AverageLoss
        - class_path: eva.metrics.MulticlassClassificationMetrics
          init_args:
            num_classes: *NUM_CLASSES
data:
  class_path: eva.DataModule
  init_args:
    datasets:
      train:
        class_path: medmnist.OrganCMNIST
        init_args: &DATASET_ARGS
          split: train
          size: 224
          download: ${oc.env:DOWNLOAD_DATA, false}
          # Set `download: true` to download the dataset from https://zenodo.org/records/10519652
          # The MedMNIST dataset is distributed under the following license: "CC BY 4.0 LEGAL CODE"
          # (see: https://creativecommons.org/licenses/by/4.0/legalcode)
          transform:
            class_path: torchvision.transforms.v2.Compose
            init_args:
              transforms:
                - class_path: torchvision.transforms.ToTensor
                - class_path: torchvision.transforms.v2.Normalize
                  init_args:
                    mean: ${oc.env:NORMALIZE_MEAN, [0.485, 0.456, 0.406]} 
                    std: ${oc.env:NORMALIZE_STD, [0.229, 0.224, 0.225]}
          target_transform:
            class_path: eva.core.data.transforms.ArraySqueeze
      val:
        class_path: medmnist.OrganCMNIST
        init_args:
          <<: *DATASET_ARGS
          split: val
      test:
        class_path: medmnist.OrganCMNIST
        init_args:
          <<: *DATASET_ARGS
          split: test
    dataloaders:
      train:
        batch_size: &BATCH_SIZE ${oc.env:BATCH_SIZE, 256}
        num_workers: &N_DATA_WORKERS ${oc.env:N_DATA_WORKERS, 4}
        shuffle: true
      val:
        batch_size: *BATCH_SIZE
      test:
        batch_size: *BATCH_SIZE
